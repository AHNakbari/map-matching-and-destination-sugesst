{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# AI Project - Phase 2 (Destination Suggestion)\n",
    "<div style=\"text-align: center\">\n",
    "<h1 style = \"color: red\"> Sharif University Of Technology</h1>\n",
    "<h2 style = \"color: green\"> DR. Mahdieh Soleymani | DR. MohammadHossein Rohban </h2>\n",
    "<h3 style = \"color: cyan\"> Head of Project: AmirHossein Razlighi <h3>\n",
    "<h3 style = \"color: cyan\"> Designed By: AmirHossein Razlighi, Javad Hezareh, Payam Taebi, Alireza Sakhaei, Ali Banayeean, Yalda Shabanzadeh, Hamidreza Yaghoubi, Alireza Heidari <h3>\n",
    "<h4 style = \"color: white\"> Ask your questions via quera</h4>\n",
    "<h5> Save your file with format: STUDENT NUMBER_Phase2.ipynb or .zip </h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div style=\"text-align: center\">\n",
    "<img src=\"./Images/Uber_research.jpg\" width=\"100%\" height=\"auto\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Suppose you are a research engineer at Uber and you are asked to design a system that suggests destinations to the passengers. The system should be able to suggest destinations based on the passenger's history. For example, one passenger may save a variety of locations (like home, work, gym, etc.). This passenger may go to gym, often on weekends and when he/she requests a car from Home. \n",
    "\n",
    "So, for example, if I am a student, going to university usually from Saturday to Wednesday on 8:00 from \"home\", the next time I request a car from \"home\" on 8:00, the system should suggest \"university\" as the destination. Now, it's not that simple always, so we should seek for smart wayys to solve this problem!\n",
    "\n",
    "As you may understood by now, we should engineer some of features from the data we have and try to predict the next destination of the passenger.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\mobilee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\mobilee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\mobilee\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mobilee\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\geopandas\\_compat.py:124: UserWarning: The Shapely GEOS version (3.11.2-CAPI-1.17.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from keplergl import KeplerGl\n",
    "\n",
    "random.seed(2024)\n",
    "np.random.seed(2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# First Approach: Using KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Preparation for KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this part, you should prepare the data for KNN. You should load the dataset file that we provided, named `Data/output.json` and then clean it, do all the required preprocessings and then split into train-test-val sets if necessary. Note that we provided a splitted test set for you, named `Data/output_test.json`. You should not use this file for training or validation. You should only use it for testing your model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  Day  origin lat  origin lon  dest lat  dest lon  \\\n0        0    0      35.625      51.375    36.000    51.085   \n1        0    0      36.000      51.085    35.625    51.375   \n2        0    0      35.680      51.445    35.745    51.465   \n3        0    0      35.745      51.465    35.680    51.445   \n4        0    1      35.625      51.375    35.680    51.445   \n\n           start_time            end_time  price  \n0 2024-01-30 13:07:00 2024-01-30 14:43:00  43.99  \n1 2024-01-30 15:13:00 2024-01-30 16:49:00  36.66  \n2 2024-01-30 20:41:00 2024-01-30 20:54:00  15.08  \n3 2024-01-30 21:24:00 2024-01-30 21:37:00  10.00  \n4 2024-01-30 23:38:00 2024-01-30 23:58:00  19.48  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>Day</th>\n      <th>origin lat</th>\n      <th>origin lon</th>\n      <th>dest lat</th>\n      <th>dest lon</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>35.625</td>\n      <td>51.375</td>\n      <td>36.000</td>\n      <td>51.085</td>\n      <td>2024-01-30 13:07:00</td>\n      <td>2024-01-30 14:43:00</td>\n      <td>43.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>36.000</td>\n      <td>51.085</td>\n      <td>35.625</td>\n      <td>51.375</td>\n      <td>2024-01-30 15:13:00</td>\n      <td>2024-01-30 16:49:00</td>\n      <td>36.66</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>35.680</td>\n      <td>51.445</td>\n      <td>35.745</td>\n      <td>51.465</td>\n      <td>2024-01-30 20:41:00</td>\n      <td>2024-01-30 20:54:00</td>\n      <td>15.08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>35.745</td>\n      <td>51.465</td>\n      <td>35.680</td>\n      <td>51.445</td>\n      <td>2024-01-30 21:24:00</td>\n      <td>2024-01-30 21:37:00</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>35.625</td>\n      <td>51.375</td>\n      <td>35.680</td>\n      <td>51.445</td>\n      <td>2024-01-30 23:38:00</td>\n      <td>2024-01-30 23:58:00</td>\n      <td>19.48</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('Data/output.json')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  Day  origin lat  origin lon  dest lat  dest lon  \\\n0       24    6      35.650      51.225    35.640    51.270   \n1       46    2      35.625      51.250    35.690    51.295   \n2       27    5      35.650      51.225    35.865    51.045   \n3        7    4      35.875      51.375    35.890    51.315   \n4       27    3      35.625      51.375    35.650    51.385   \n\n           start_time            end_time  price  \n0 2024-01-30 11:58:00 2024-01-30 12:12:00  10.00  \n1 2024-01-30 21:58:00 2024-01-30 22:18:00  11.84  \n2 2024-01-30 20:05:00 2024-01-30 20:58:00  23.36  \n3 2024-01-30 17:39:00 2024-01-30 18:17:00  13.74  \n4 2024-01-30 13:16:00 2024-01-30 13:19:00  15.08  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>Day</th>\n      <th>origin lat</th>\n      <th>origin lon</th>\n      <th>dest lat</th>\n      <th>dest lon</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24</td>\n      <td>6</td>\n      <td>35.650</td>\n      <td>51.225</td>\n      <td>35.640</td>\n      <td>51.270</td>\n      <td>2024-01-30 11:58:00</td>\n      <td>2024-01-30 12:12:00</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46</td>\n      <td>2</td>\n      <td>35.625</td>\n      <td>51.250</td>\n      <td>35.690</td>\n      <td>51.295</td>\n      <td>2024-01-30 21:58:00</td>\n      <td>2024-01-30 22:18:00</td>\n      <td>11.84</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>27</td>\n      <td>5</td>\n      <td>35.650</td>\n      <td>51.225</td>\n      <td>35.865</td>\n      <td>51.045</td>\n      <td>2024-01-30 20:05:00</td>\n      <td>2024-01-30 20:58:00</td>\n      <td>23.36</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>4</td>\n      <td>35.875</td>\n      <td>51.375</td>\n      <td>35.890</td>\n      <td>51.315</td>\n      <td>2024-01-30 17:39:00</td>\n      <td>2024-01-30 18:17:00</td>\n      <td>13.74</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>3</td>\n      <td>35.625</td>\n      <td>51.375</td>\n      <td>35.650</td>\n      <td>51.385</td>\n      <td>2024-01-30 13:16:00</td>\n      <td>2024-01-30 13:19:00</td>\n      <td>15.08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_json('Data/output_test.json')\n",
    "df_test.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### missing values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "user_id       0\nDay           0\norigin lat    0\norigin lon    0\ndest lat      0\ndest lon      0\nstart_time    0\nend_time      0\nprice         0\ndtype: int64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Handling missing Values \"\"\"\n",
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### feature engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    # time features\n",
    "    df['hour_of_start'] = df['start_time'].dt.hour\n",
    "    df['day_of_start'] = df['start_time'].dt.day\n",
    "    df['trip_duration'] = (df['end_time'] - df['start_time']).dt.total_seconds() / 60\n",
    "\n",
    "    # origin loc features\n",
    "    # df[['origin_label', 'origin_coordinate']] = pd.DataFrame(df['origin'].tolist(), index=df.index)\n",
    "    # df[['origin_lat', 'origin_lon']] = pd.DataFrame(df['origin_coordinate'].tolist(), index=df.index)\n",
    "\n",
    "    # destination loc features\n",
    "    # df[['destination_label', 'destination_coordinate']] = pd.DataFrame(df['destination'].tolist(), index=df.index)\n",
    "    # df[['destination_lat', 'destination_lon']] = pd.DataFrame(df['destination_coordinate'].tolist(), index=df.index)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       user_id  Day  origin lat  origin lon  dest lat  dest lon  \\\n0            0    0      35.625      51.375    36.000    51.085   \n1            0    0      36.000      51.085    35.625    51.375   \n2            0    0      35.680      51.445    35.745    51.465   \n3            0    0      35.745      51.465    35.680    51.445   \n4            0    1      35.625      51.375    35.680    51.445   \n...        ...  ...         ...         ...       ...       ...   \n17989       59    0      35.950      51.225    35.875    51.125   \n17990       59    0      35.875      51.125    35.690    51.295   \n17991       59    0      35.875      51.125    35.525    51.100   \n17992       59    0      35.525      51.100    35.815    51.320   \n17993       59    0      35.815      51.320    35.950    51.225   \n\n               start_time            end_time  price  hour_of_start  \\\n0     2024-01-30 13:07:00 2024-01-30 14:43:00  43.99             13   \n1     2024-01-30 15:13:00 2024-01-30 16:49:00  36.66             15   \n2     2024-01-30 20:41:00 2024-01-30 20:54:00  15.08             20   \n3     2024-01-30 21:24:00 2024-01-30 21:37:00  10.00             21   \n4     2024-01-30 23:38:00 2024-01-30 23:58:00  19.48             23   \n...                   ...                 ...    ...            ...   \n17989 2024-01-30 06:41:00 2024-01-30 07:07:00  10.92              6   \n17990 2024-01-30 12:46:00 2024-01-30 13:35:00  17.35             12   \n17991 2024-01-30 17:39:00 2024-01-30 18:48:00  34.56             17   \n17992 2024-01-30 20:09:00 2024-01-30 21:19:00  36.80             20   \n17993 2024-01-30 21:49:00 2024-01-30 22:21:00  11.22             21   \n\n       day_of_start  trip_duration  \n0                30           96.0  \n1                30           96.0  \n2                30           13.0  \n3                30           13.0  \n4                30           20.0  \n...             ...            ...  \n17989            30           26.0  \n17990            30           49.0  \n17991            30           69.0  \n17992            30           70.0  \n17993            30           32.0  \n\n[17994 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>Day</th>\n      <th>origin lat</th>\n      <th>origin lon</th>\n      <th>dest lat</th>\n      <th>dest lon</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>price</th>\n      <th>hour_of_start</th>\n      <th>day_of_start</th>\n      <th>trip_duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>35.625</td>\n      <td>51.375</td>\n      <td>36.000</td>\n      <td>51.085</td>\n      <td>2024-01-30 13:07:00</td>\n      <td>2024-01-30 14:43:00</td>\n      <td>43.99</td>\n      <td>13</td>\n      <td>30</td>\n      <td>96.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>36.000</td>\n      <td>51.085</td>\n      <td>35.625</td>\n      <td>51.375</td>\n      <td>2024-01-30 15:13:00</td>\n      <td>2024-01-30 16:49:00</td>\n      <td>36.66</td>\n      <td>15</td>\n      <td>30</td>\n      <td>96.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>35.680</td>\n      <td>51.445</td>\n      <td>35.745</td>\n      <td>51.465</td>\n      <td>2024-01-30 20:41:00</td>\n      <td>2024-01-30 20:54:00</td>\n      <td>15.08</td>\n      <td>20</td>\n      <td>30</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>35.745</td>\n      <td>51.465</td>\n      <td>35.680</td>\n      <td>51.445</td>\n      <td>2024-01-30 21:24:00</td>\n      <td>2024-01-30 21:37:00</td>\n      <td>10.00</td>\n      <td>21</td>\n      <td>30</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>35.625</td>\n      <td>51.375</td>\n      <td>35.680</td>\n      <td>51.445</td>\n      <td>2024-01-30 23:38:00</td>\n      <td>2024-01-30 23:58:00</td>\n      <td>19.48</td>\n      <td>23</td>\n      <td>30</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17989</th>\n      <td>59</td>\n      <td>0</td>\n      <td>35.950</td>\n      <td>51.225</td>\n      <td>35.875</td>\n      <td>51.125</td>\n      <td>2024-01-30 06:41:00</td>\n      <td>2024-01-30 07:07:00</td>\n      <td>10.92</td>\n      <td>6</td>\n      <td>30</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>17990</th>\n      <td>59</td>\n      <td>0</td>\n      <td>35.875</td>\n      <td>51.125</td>\n      <td>35.690</td>\n      <td>51.295</td>\n      <td>2024-01-30 12:46:00</td>\n      <td>2024-01-30 13:35:00</td>\n      <td>17.35</td>\n      <td>12</td>\n      <td>30</td>\n      <td>49.0</td>\n    </tr>\n    <tr>\n      <th>17991</th>\n      <td>59</td>\n      <td>0</td>\n      <td>35.875</td>\n      <td>51.125</td>\n      <td>35.525</td>\n      <td>51.100</td>\n      <td>2024-01-30 17:39:00</td>\n      <td>2024-01-30 18:48:00</td>\n      <td>34.56</td>\n      <td>17</td>\n      <td>30</td>\n      <td>69.0</td>\n    </tr>\n    <tr>\n      <th>17992</th>\n      <td>59</td>\n      <td>0</td>\n      <td>35.525</td>\n      <td>51.100</td>\n      <td>35.815</td>\n      <td>51.320</td>\n      <td>2024-01-30 20:09:00</td>\n      <td>2024-01-30 21:19:00</td>\n      <td>36.80</td>\n      <td>20</td>\n      <td>30</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>17993</th>\n      <td>59</td>\n      <td>0</td>\n      <td>35.815</td>\n      <td>51.320</td>\n      <td>35.950</td>\n      <td>51.225</td>\n      <td>2024-01-30 21:49:00</td>\n      <td>2024-01-30 22:21:00</td>\n      <td>11.22</td>\n      <td>21</td>\n      <td>30</td>\n      <td>32.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17994 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = feature_engineering(df)\n",
    "df_test = feature_engineering(df_test)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique users: 60\n",
      "randomly selected user: 30\n"
     ]
    }
   ],
   "source": [
    "# print out the number of unique users and also randomly select one user\n",
    "print(\"number of unique users:\", df['user_id'].nunique())\n",
    "selected_user = random.choice(df['user_id'].unique())\n",
    "print(\"randomly selected user:\", selected_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "data": {
      "text/plain": "KeplerGl(data={'destinations': {'index': [8883, 8884, 8885, 8886, 8887, 8888, 8889, 8890, 8891, 8892, 8893, 88…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67c6122718d54b30aeb3cf8c433e1d1c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract data for the selected user\n",
    "user_data = df[df['user_id'] == selected_user]\n",
    "\n",
    "# Extract destinations from user_data as lat-long pairs\n",
    "destinations = user_data[['dest lat', 'dest lon']]\n",
    "destinations.columns = ['latitude', 'longitude']\n",
    "\n",
    "# Visualize the destinations\n",
    "map_1 = KeplerGl(height=500)\n",
    "map_1.add_data(data=destinations, name='destinations')\n",
    "map_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, you should do feature engineering stuff! Extract the features that you think are important. Split the features into training set and also extract the related outputs (used for our model further). These outputs may be strings (name of destination) or destination's latitude/longitude or etc. Use your creativity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def categorical_to_numerical(df):\n",
    "    # One-hot encode 'origin_label'\n",
    "    onehot_encoder = OneHotEncoder()\n",
    "    onehot_encoded = onehot_encoder.fit_transform(df[['origin_label']]).toarray()\n",
    "\n",
    "    # Drop the original 'origin_label' column and add the new one-hot encoded columns\n",
    "    df = df.drop('origin_label', axis=1)\n",
    "    df[onehot_encoder.get_feature_names_out(['origin_label'])] = onehot_encoded\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df[['user_id', 'Day', 'hour_of_start', 'day_of_start', 'trip_duration', 'origin lat', 'origin lon', 'price']]\n",
    "# X = categorical_to_numerical(X)\n",
    "y = df[['dest lat', 'dest lon']]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "X_test = df_test[['user_id', 'Day', 'hour_of_start', 'day_of_start', 'trip_duration', 'origin lat', 'origin lon', 'price']]\n",
    "# X_test = categorical_to_numerical(X_test)\n",
    "y_test = df_test[['dest lat', 'dest lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "       user_id  Day  hour_of_start  day_of_start  trip_duration  origin lat  \\\n9523        32    4              6            30           28.0      35.725   \n10784       36    4              7            30           22.0      35.735   \n221          0    5             16            30           42.0      35.520   \n11535       38    3              7            30           13.0      35.710   \n10793       36    1             12            30           25.0      35.625   \n...        ...  ...            ...           ...            ...         ...   \n16567       55    2             12            30           40.0      35.625   \n2494         9    4              7            30            5.0      35.615   \n14875       50    6             12            30           49.0      35.975   \n2688         9    3             12            30           18.0      35.625   \n7816        26    0             16            30           34.0      35.875   \n\n       origin lon  price  \n9523       51.300  21.27  \n10784      51.200  16.41  \n221        51.285  27.34  \n11535      51.090  17.50  \n10793      51.125  18.60  \n...           ...    ...  \n16567      51.250  22.13  \n2494       51.175  13.85  \n14875      51.250  24.80  \n2688       51.125  10.74  \n7816       51.125  21.08  \n\n[14395 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>Day</th>\n      <th>hour_of_start</th>\n      <th>day_of_start</th>\n      <th>trip_duration</th>\n      <th>origin lat</th>\n      <th>origin lon</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9523</th>\n      <td>32</td>\n      <td>4</td>\n      <td>6</td>\n      <td>30</td>\n      <td>28.0</td>\n      <td>35.725</td>\n      <td>51.300</td>\n      <td>21.27</td>\n    </tr>\n    <tr>\n      <th>10784</th>\n      <td>36</td>\n      <td>4</td>\n      <td>7</td>\n      <td>30</td>\n      <td>22.0</td>\n      <td>35.735</td>\n      <td>51.200</td>\n      <td>16.41</td>\n    </tr>\n    <tr>\n      <th>221</th>\n      <td>0</td>\n      <td>5</td>\n      <td>16</td>\n      <td>30</td>\n      <td>42.0</td>\n      <td>35.520</td>\n      <td>51.285</td>\n      <td>27.34</td>\n    </tr>\n    <tr>\n      <th>11535</th>\n      <td>38</td>\n      <td>3</td>\n      <td>7</td>\n      <td>30</td>\n      <td>13.0</td>\n      <td>35.710</td>\n      <td>51.090</td>\n      <td>17.50</td>\n    </tr>\n    <tr>\n      <th>10793</th>\n      <td>36</td>\n      <td>1</td>\n      <td>12</td>\n      <td>30</td>\n      <td>25.0</td>\n      <td>35.625</td>\n      <td>51.125</td>\n      <td>18.60</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16567</th>\n      <td>55</td>\n      <td>2</td>\n      <td>12</td>\n      <td>30</td>\n      <td>40.0</td>\n      <td>35.625</td>\n      <td>51.250</td>\n      <td>22.13</td>\n    </tr>\n    <tr>\n      <th>2494</th>\n      <td>9</td>\n      <td>4</td>\n      <td>7</td>\n      <td>30</td>\n      <td>5.0</td>\n      <td>35.615</td>\n      <td>51.175</td>\n      <td>13.85</td>\n    </tr>\n    <tr>\n      <th>14875</th>\n      <td>50</td>\n      <td>6</td>\n      <td>12</td>\n      <td>30</td>\n      <td>49.0</td>\n      <td>35.975</td>\n      <td>51.250</td>\n      <td>24.80</td>\n    </tr>\n    <tr>\n      <th>2688</th>\n      <td>9</td>\n      <td>3</td>\n      <td>12</td>\n      <td>30</td>\n      <td>18.0</td>\n      <td>35.625</td>\n      <td>51.125</td>\n      <td>10.74</td>\n    </tr>\n    <tr>\n      <th>7816</th>\n      <td>26</td>\n      <td>0</td>\n      <td>16</td>\n      <td>30</td>\n      <td>34.0</td>\n      <td>35.875</td>\n      <td>51.125</td>\n      <td>21.08</td>\n    </tr>\n  </tbody>\n</table>\n<p>14395 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (14395, 8)\n",
      "y_train shape: (14395, 2)\n",
      "X_val shape: (3599, 8)\n",
      "y_val shape: (3599, 2)\n",
      "X_test shape: (4499, 8)\n",
      "y_test shape: (4499, 2)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('y_val shape:', y_val.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this section, we are going to implement our KNN model. For further information on how KNN works, please refer to [this](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) link. As you can see, it's a simple algorithm. We will start with this and see the results of our _destination suggestion_ system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NearestNeighbor():\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.train_X = None\n",
    "        self.train_y = None\n",
    "\n",
    "    def fit(self, train_X, train_y):\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "\n",
    "    def predict(self, x):\n",
    "        predictions = []\n",
    "        for i in range(x.shape[0]):\n",
    "            distances = self.calculate_distances(x.iloc[i, :])\n",
    "            k_nearest_indices = np.argsort(distances)[:self.k]\n",
    "            k_nearest_labels = self.train_y.iloc[k_nearest_indices]\n",
    "            average_label = np.mean(k_nearest_labels, axis=0)\n",
    "            predictions.append(average_label)\n",
    "        return pd.DataFrame(predictions, columns=self.train_y.columns)\n",
    "\n",
    "    def calculate_distances(self, x):\n",
    "        distances = np.sqrt(np.sum((self.train_X - x) ** 2, axis=1))\n",
    "        return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred, tolerance=0):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = y_true.shape[0]\n",
    "\n",
    "    for true, pred in zip(y_true.values, y_pred.values):\n",
    "        lat_correct = abs(true[0] - pred[0]) <= tolerance\n",
    "        lon_correct = abs(true[1] - pred[1]) <= tolerance\n",
    "        if lat_correct and lon_correct:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "knn_model = NearestNeighbor(k=1)\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 99.98610628690517\n"
     ]
    }
   ],
   "source": [
    "train_predictions_KNN = knn_model.predict(X_train)\n",
    "train_accuracy_KNN = calculate_accuracy(y_train, train_predictions_KNN)\n",
    "print(f\"Training Accuracy: {train_accuracy_KNN*100}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 37.14920811336482\n"
     ]
    }
   ],
   "source": [
    "val_predictions_KNN = knn_model.predict(X_val)\n",
    "val_accuracy_KNN = calculate_accuracy(y_val, val_predictions_KNN)\n",
    "print(f\"Validation Accuracy: {val_accuracy_KNN*100}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 38.986441431429206\n"
     ]
    }
   ],
   "source": [
    "test_predictions_KNN = knn_model.predict(X_test)\n",
    "test_accuracy_KNN = calculate_accuracy(y_test, test_predictions_KNN)\n",
    "print(f\"Test Accuracy: {test_accuracy_KNN*100}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**QUESTION**: What do you think about this approach? Is it a good idea to use KNN for this problem? Why (or why not)? If the patterns in our datatset (passengers' history) get more complicated, will our model be robust to it in comparison to other models?\n",
    "\n",
    "Your Answer:\n",
    "\n",
    "***\n",
    "\n",
    "***While KNN can be a good starting point due to its simplicity, the current results suggest it might not be the best choice for this particular problem, especially as the complexity of the data increases. Exploring more complex models and refining the feature engineering process could lead to better generalization and improved performance on unseen data.***\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Second Approach: Using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this part, we are going to use XGBoost to predict the next destination of the passenger. You can use `xgboost` library to implement this model. To learn more about XGBoost, please refer to [this](https://en.wikipedia.org/wiki/XGBoost) link. It should be familiar to you, as you saw decision trees in the class.\n",
    "\n",
    "For this part, you can use the same data (that you did all the processes on) from the previous part. Or, if you need, you can reload the dataset and do new preprocessings on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can see the overview of how XGBoost works in the image below:\n",
    "\n",
    "<dev style=\"text-align: center\">\n",
    "<img src=\"./Images/XGBoost.png\" />\n",
    "</dev>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Although, this is for more information and you **do not** need to implement `XGBoost` from scratch. You can use the library that we mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self):\n",
    "      self.trans_dic={}\n",
    "      self.invtrans_dic={}\n",
    "      self.j=0\n",
    "\n",
    "    def fit(self, y):\n",
    "      y2 = y.to_numpy()\n",
    "      for i in range(len(y2)):\n",
    "        if (y2[i][0] , y2[i][1]) not in self.trans_dic:\n",
    "          self.trans_dic[(y2[i][0] , y2[i][1])]= self.j\n",
    "          self.invtrans_dic[self.j]= y2[i]\n",
    "          self.j+=1\n",
    "      return self.transform(y2)\n",
    "\n",
    "    def transform(self, y):\n",
    "      ny= []\n",
    "      for i in range(len(y)):\n",
    "        ny.append(self.trans_dic[(y[i][0] , y[i][1])])\n",
    "      return ny\n",
    "\n",
    "    def inverse_transform(self, enc):\n",
    "      ny= []\n",
    "      for i in range(len(enc)):\n",
    "        ny.append(self.invtrans_dic[enc[i]])\n",
    "\n",
    "      return np.array(ny)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def predict_XG(encoder, classifier, X):\n",
    "      X = X.to_numpy()\n",
    "      X = np.array(X, dtype=np.float64)\n",
    "      prediction = classifier.predict(X)\n",
    "      return encoder.inverse_transform(prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, objective='multi:softmax', ...)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = xgb.XGBClassifier(objective='multi:softmax')\n",
    "enc = Encoder()\n",
    "\n",
    "y_train_XG = enc.fit(y_train)\n",
    "X_train_XG = X_train.to_numpy()\n",
    "X_train_XG = np.array(X_train_XG,dtype=np.float64)\n",
    "\n",
    "classifier.fit(X_train_XG, y_train_XG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 99.97915943035777\n"
     ]
    }
   ],
   "source": [
    "train_predictions_XGB = predict_XG(encoder=enc, classifier=classifier, X=X_train)\n",
    "train_accuracy_XGB = calculate_accuracy(y_train, pd.DataFrame(train_predictions_XGB))\n",
    "print(f\"Training Accuracy: {train_accuracy_XGB*100}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 73.24256737982773\n"
     ]
    }
   ],
   "source": [
    "val_predictions_XGB = predict_XG(encoder=enc, classifier=classifier, X=X_val)\n",
    "val_accuracy_XGB = calculate_accuracy(y_val, pd.DataFrame(val_predictions_XGB))\n",
    "print(f\"Validation Accuracy: {val_accuracy_XGB*100}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.79417648366304\n"
     ]
    }
   ],
   "source": [
    "test_predictions_XGB = predict_XG(encoder=enc, classifier=classifier, X=X_test)\n",
    "test_accuracy_XGB = calculate_accuracy(y_test, pd.DataFrame(test_predictions_XGB))\n",
    "print(f\"Test Accuracy: {test_accuracy_XGB*100}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**QUESTION**: What do you think about this approach? Is it a good idea to use XGBoost for this problem? Why (or why not)? If the patterns in our datatset (passengers' history) get more complicated, will our model be robust to it in comparison to other models?\n",
    "\n",
    "Your Answer:\n",
    "***\n",
    "\n",
    "***Using XGBoost is a good choice for this problem, particularly given its significant improvement in test accuracy (73%) compared to KNN (33%). XGBoost is known for handling structured data efficiently and dealing well with a mix of numerical and categorical features. It's also robust to overfitting and capable of capturing complex patterns in data, which suggests it could continue to perform well as the dataset's complexity increases. However, while XGBoost offers better performance and scalability than KNN, it may still be less interpretable than simpler models and requires careful tuning of its hyperparameters.***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Question**: Please explain the problem of overfitting in XGBoost. How can you solve it? Provide a brief explanation.\n",
    "\n",
    "Your Answer:\n",
    "\n",
    "***\n",
    "\n",
    "***Overfitting in XGBoost occurs when the model learns the training data too well, including its noise and outliers, leading to poor generalization on unseen data. This is often due to excessively complex models with too many trees or trees that are too deep. To solve overfitting in XGBoost, you can:\n",
    "Limit the complexity of the individual trees by setting a maximum depth (max_depth) and minimum child weight (min_child_weight).\n",
    "Use regularization parameters like gamma (minimum loss reduction for further partition), lambda (L2 regularization), and alpha (L1 regularization) to penalize complex models.\n",
    "Implement early stopping to halt training when the performance on a validation set stops improving.\n",
    "Reduce the learning rate (eta) and increase the number of boosting rounds (n_estimators) for more gradual learning.\n",
    "These measures help in creating a more generalized model that performs better on unseen data.***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Third Approach: Classifier Using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this approach, we are going to use a classifier using neural networks. You can think of this approach and how to model the problem as a classification problem in many ways! So, we are not going to restrict your creativity. Just a hint: You can consider each of the unique destinations (in whole dataset) as a class and then train a classifier to classify the destinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data for Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's prepare the data for our neural network. Again, you should extract required features from the dataset and then split the dataset into train-test-val sets if necessary. For your ease, we prepared another version of `output.json` that helps you to extract features for this part, easier. So, please load `Data/trip_data.json` and use it for training set and validation set. You should use `Data/trip_data_test.json` for testing your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  Day                          origin  \\\n0        0    0        [work, [35.625, 51.375]]   \n1        0    0    [restaurant, [36.0, 51.085]]   \n2        0    0         [home, [35.68, 51.445]]   \n3        0    0  [restaurant, [35.745, 51.465]]   \n4        0    1        [work, [35.625, 51.375]]   \n\n                      destination          start_time            end_time  \\\n0    [restaurant, [36.0, 51.085]] 2024-01-30 13:07:00 2024-01-30 14:43:00   \n1        [work, [35.625, 51.375]] 2024-01-30 15:13:00 2024-01-30 16:49:00   \n2  [restaurant, [35.745, 51.465]] 2024-01-30 20:41:00 2024-01-30 20:54:00   \n3         [home, [35.68, 51.445]] 2024-01-30 21:24:00 2024-01-30 21:37:00   \n4         [home, [35.68, 51.445]] 2024-01-30 23:38:00 2024-01-30 23:58:00   \n\n   price  \n0  43.99  \n1  36.66  \n2  15.08  \n3  10.00  \n4  19.48  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>Day</th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>[work, [35.625, 51.375]]</td>\n      <td>[restaurant, [36.0, 51.085]]</td>\n      <td>2024-01-30 13:07:00</td>\n      <td>2024-01-30 14:43:00</td>\n      <td>43.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>[restaurant, [36.0, 51.085]]</td>\n      <td>[work, [35.625, 51.375]]</td>\n      <td>2024-01-30 15:13:00</td>\n      <td>2024-01-30 16:49:00</td>\n      <td>36.66</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>[home, [35.68, 51.445]]</td>\n      <td>[restaurant, [35.745, 51.465]]</td>\n      <td>2024-01-30 20:41:00</td>\n      <td>2024-01-30 20:54:00</td>\n      <td>15.08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>[restaurant, [35.745, 51.465]]</td>\n      <td>[home, [35.68, 51.445]]</td>\n      <td>2024-01-30 21:24:00</td>\n      <td>2024-01-30 21:37:00</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>[work, [35.625, 51.375]]</td>\n      <td>[home, [35.68, 51.445]]</td>\n      <td>2024-01-30 23:38:00</td>\n      <td>2024-01-30 23:58:00</td>\n      <td>19.48</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_json('Data/trip_data.json')\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  Day                         origin  \\\n0       24    6        [pool, [35.65, 51.225]]   \n1       46    2  [university, [35.625, 51.25]]   \n2       27    5        [pool, [35.65, 51.225]]   \n3        7    4       [work, [35.875, 51.375]]   \n4       27    3       [work, [35.625, 51.375]]   \n\n                      destination          start_time            end_time  \\\n0          [home, [35.64, 51.27]] 2024-01-30 11:58:00 2024-01-30 12:12:00   \n1   [restaurant, [35.69, 51.295]] 2024-01-30 21:58:00 2024-01-30 22:18:00   \n2  [restaurant, [35.865, 51.045]] 2024-01-30 20:05:00 2024-01-30 20:58:00   \n3         [home, [35.89, 51.315]] 2024-01-30 17:39:00 2024-01-30 18:17:00   \n4   [restaurant, [35.65, 51.385]] 2024-01-30 13:16:00 2024-01-30 13:19:00   \n\n   price  \n0  10.00  \n1  11.84  \n2  23.36  \n3  13.74  \n4  15.08  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>Day</th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24</td>\n      <td>6</td>\n      <td>[pool, [35.65, 51.225]]</td>\n      <td>[home, [35.64, 51.27]]</td>\n      <td>2024-01-30 11:58:00</td>\n      <td>2024-01-30 12:12:00</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46</td>\n      <td>2</td>\n      <td>[university, [35.625, 51.25]]</td>\n      <td>[restaurant, [35.69, 51.295]]</td>\n      <td>2024-01-30 21:58:00</td>\n      <td>2024-01-30 22:18:00</td>\n      <td>11.84</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>27</td>\n      <td>5</td>\n      <td>[pool, [35.65, 51.225]]</td>\n      <td>[restaurant, [35.865, 51.045]]</td>\n      <td>2024-01-30 20:05:00</td>\n      <td>2024-01-30 20:58:00</td>\n      <td>23.36</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>4</td>\n      <td>[work, [35.875, 51.375]]</td>\n      <td>[home, [35.89, 51.315]]</td>\n      <td>2024-01-30 17:39:00</td>\n      <td>2024-01-30 18:17:00</td>\n      <td>13.74</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>3</td>\n      <td>[work, [35.625, 51.375]]</td>\n      <td>[restaurant, [35.65, 51.385]]</td>\n      <td>2024-01-30 13:16:00</td>\n      <td>2024-01-30 13:19:00</td>\n      <td>15.08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_json('Data/trip_data_test.json')\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def feature_engineering_neural_net(df):\n",
    "    # time features\n",
    "    df['hour_of_start'] = df['start_time'].dt.hour\n",
    "    # df['day_of_start'] = df['start_time'].dt.day\n",
    "    df['trip_duration'] = (df['end_time'] - df['start_time']).dt.total_seconds() / 60\n",
    "\n",
    "    # origin loc features\n",
    "    df[['origin_label', 'origin_coordinate']] = pd.DataFrame(df['origin'].tolist(), index=df.index)\n",
    "    df[['origin_lat', 'origin_lon']] = pd.DataFrame(df['origin_coordinate'].tolist(), index=df.index)\n",
    "\n",
    "    # destination loc features\n",
    "    df[['destination_label', 'destination_coordinate']] = pd.DataFrame(df['destination'].tolist(), index=df.index)\n",
    "    df[['destination_lat', 'destination_lon']] = pd.DataFrame(df['destination_coordinate'].tolist(), index=df.index)\n",
    "\n",
    "    # encode the origin and destination labels\n",
    "    all_labels = pd.concat([df['origin_label'], df['destination_label']])\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(all_labels)\n",
    "    df['origin_label'] = label_encoder.transform(df['origin_label'])\n",
    "    df['destination_label'] = label_encoder.transform(df['destination_label'])\n",
    "\n",
    "    return df, label_encoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       user_id  Day                          origin  \\\n0            0    0        [work, [35.625, 51.375]]   \n1            0    0    [restaurant, [36.0, 51.085]]   \n2            0    0         [home, [35.68, 51.445]]   \n3            0    0  [restaurant, [35.745, 51.465]]   \n4            0    1        [work, [35.625, 51.375]]   \n...        ...  ...                             ...   \n17989       59    0         [home, [35.95, 51.225]]   \n17990       59    0        [work, [35.875, 51.125]]   \n17991       59    0        [work, [35.875, 51.125]]   \n17992       59    0          [pool, [35.525, 51.1]]   \n17993       59    0   [restaurant, [35.815, 51.32]]   \n\n                          destination          start_time            end_time  \\\n0        [restaurant, [36.0, 51.085]] 2024-01-30 13:07:00 2024-01-30 14:43:00   \n1            [work, [35.625, 51.375]] 2024-01-30 15:13:00 2024-01-30 16:49:00   \n2      [restaurant, [35.745, 51.465]] 2024-01-30 20:41:00 2024-01-30 20:54:00   \n3             [home, [35.68, 51.445]] 2024-01-30 21:24:00 2024-01-30 21:37:00   \n4             [home, [35.68, 51.445]] 2024-01-30 23:38:00 2024-01-30 23:58:00   \n...                               ...                 ...                 ...   \n17989        [work, [35.875, 51.125]] 2024-01-30 06:41:00 2024-01-30 07:07:00   \n17990   [restaurant, [35.69, 51.295]] 2024-01-30 12:46:00 2024-01-30 13:35:00   \n17991          [pool, [35.525, 51.1]] 2024-01-30 17:39:00 2024-01-30 18:48:00   \n17992   [restaurant, [35.815, 51.32]] 2024-01-30 20:09:00 2024-01-30 21:19:00   \n17993         [home, [35.95, 51.225]] 2024-01-30 21:49:00 2024-01-30 22:21:00   \n\n       price  hour_of_start  trip_duration  origin_label origin_coordinate  \\\n0      43.99             13           96.0             6  [35.625, 51.375]   \n1      36.66             15           96.0             4    [36.0, 51.085]   \n2      15.08             20           13.0             1   [35.68, 51.445]   \n3      10.00             21           13.0             4  [35.745, 51.465]   \n4      19.48             23           20.0             6  [35.625, 51.375]   \n...      ...            ...            ...           ...               ...   \n17989  10.92              6           26.0             1   [35.95, 51.225]   \n17990  17.35             12           49.0             6  [35.875, 51.125]   \n17991  34.56             17           69.0             6  [35.875, 51.125]   \n17992  36.80             20           70.0             3    [35.525, 51.1]   \n17993  11.22             21           32.0             4   [35.815, 51.32]   \n\n       origin_lat  origin_lon  destination_label destination_coordinate  \\\n0          35.625      51.375                  4         [36.0, 51.085]   \n1          36.000      51.085                  6       [35.625, 51.375]   \n2          35.680      51.445                  4       [35.745, 51.465]   \n3          35.745      51.465                  1        [35.68, 51.445]   \n4          35.625      51.375                  1        [35.68, 51.445]   \n...           ...         ...                ...                    ...   \n17989      35.950      51.225                  6       [35.875, 51.125]   \n17990      35.875      51.125                  4        [35.69, 51.295]   \n17991      35.875      51.125                  3         [35.525, 51.1]   \n17992      35.525      51.100                  4        [35.815, 51.32]   \n17993      35.815      51.320                  1        [35.95, 51.225]   \n\n       destination_lat  destination_lon  \n0               36.000           51.085  \n1               35.625           51.375  \n2               35.745           51.465  \n3               35.680           51.445  \n4               35.680           51.445  \n...                ...              ...  \n17989           35.875           51.125  \n17990           35.690           51.295  \n17991           35.525           51.100  \n17992           35.815           51.320  \n17993           35.950           51.225  \n\n[17994 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>Day</th>\n      <th>origin</th>\n      <th>destination</th>\n      <th>start_time</th>\n      <th>end_time</th>\n      <th>price</th>\n      <th>hour_of_start</th>\n      <th>trip_duration</th>\n      <th>origin_label</th>\n      <th>origin_coordinate</th>\n      <th>origin_lat</th>\n      <th>origin_lon</th>\n      <th>destination_label</th>\n      <th>destination_coordinate</th>\n      <th>destination_lat</th>\n      <th>destination_lon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>[work, [35.625, 51.375]]</td>\n      <td>[restaurant, [36.0, 51.085]]</td>\n      <td>2024-01-30 13:07:00</td>\n      <td>2024-01-30 14:43:00</td>\n      <td>43.99</td>\n      <td>13</td>\n      <td>96.0</td>\n      <td>6</td>\n      <td>[35.625, 51.375]</td>\n      <td>35.625</td>\n      <td>51.375</td>\n      <td>4</td>\n      <td>[36.0, 51.085]</td>\n      <td>36.000</td>\n      <td>51.085</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>[restaurant, [36.0, 51.085]]</td>\n      <td>[work, [35.625, 51.375]]</td>\n      <td>2024-01-30 15:13:00</td>\n      <td>2024-01-30 16:49:00</td>\n      <td>36.66</td>\n      <td>15</td>\n      <td>96.0</td>\n      <td>4</td>\n      <td>[36.0, 51.085]</td>\n      <td>36.000</td>\n      <td>51.085</td>\n      <td>6</td>\n      <td>[35.625, 51.375]</td>\n      <td>35.625</td>\n      <td>51.375</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>[home, [35.68, 51.445]]</td>\n      <td>[restaurant, [35.745, 51.465]]</td>\n      <td>2024-01-30 20:41:00</td>\n      <td>2024-01-30 20:54:00</td>\n      <td>15.08</td>\n      <td>20</td>\n      <td>13.0</td>\n      <td>1</td>\n      <td>[35.68, 51.445]</td>\n      <td>35.680</td>\n      <td>51.445</td>\n      <td>4</td>\n      <td>[35.745, 51.465]</td>\n      <td>35.745</td>\n      <td>51.465</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>[restaurant, [35.745, 51.465]]</td>\n      <td>[home, [35.68, 51.445]]</td>\n      <td>2024-01-30 21:24:00</td>\n      <td>2024-01-30 21:37:00</td>\n      <td>10.00</td>\n      <td>21</td>\n      <td>13.0</td>\n      <td>4</td>\n      <td>[35.745, 51.465]</td>\n      <td>35.745</td>\n      <td>51.465</td>\n      <td>1</td>\n      <td>[35.68, 51.445]</td>\n      <td>35.680</td>\n      <td>51.445</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>[work, [35.625, 51.375]]</td>\n      <td>[home, [35.68, 51.445]]</td>\n      <td>2024-01-30 23:38:00</td>\n      <td>2024-01-30 23:58:00</td>\n      <td>19.48</td>\n      <td>23</td>\n      <td>20.0</td>\n      <td>6</td>\n      <td>[35.625, 51.375]</td>\n      <td>35.625</td>\n      <td>51.375</td>\n      <td>1</td>\n      <td>[35.68, 51.445]</td>\n      <td>35.680</td>\n      <td>51.445</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17989</th>\n      <td>59</td>\n      <td>0</td>\n      <td>[home, [35.95, 51.225]]</td>\n      <td>[work, [35.875, 51.125]]</td>\n      <td>2024-01-30 06:41:00</td>\n      <td>2024-01-30 07:07:00</td>\n      <td>10.92</td>\n      <td>6</td>\n      <td>26.0</td>\n      <td>1</td>\n      <td>[35.95, 51.225]</td>\n      <td>35.950</td>\n      <td>51.225</td>\n      <td>6</td>\n      <td>[35.875, 51.125]</td>\n      <td>35.875</td>\n      <td>51.125</td>\n    </tr>\n    <tr>\n      <th>17990</th>\n      <td>59</td>\n      <td>0</td>\n      <td>[work, [35.875, 51.125]]</td>\n      <td>[restaurant, [35.69, 51.295]]</td>\n      <td>2024-01-30 12:46:00</td>\n      <td>2024-01-30 13:35:00</td>\n      <td>17.35</td>\n      <td>12</td>\n      <td>49.0</td>\n      <td>6</td>\n      <td>[35.875, 51.125]</td>\n      <td>35.875</td>\n      <td>51.125</td>\n      <td>4</td>\n      <td>[35.69, 51.295]</td>\n      <td>35.690</td>\n      <td>51.295</td>\n    </tr>\n    <tr>\n      <th>17991</th>\n      <td>59</td>\n      <td>0</td>\n      <td>[work, [35.875, 51.125]]</td>\n      <td>[pool, [35.525, 51.1]]</td>\n      <td>2024-01-30 17:39:00</td>\n      <td>2024-01-30 18:48:00</td>\n      <td>34.56</td>\n      <td>17</td>\n      <td>69.0</td>\n      <td>6</td>\n      <td>[35.875, 51.125]</td>\n      <td>35.875</td>\n      <td>51.125</td>\n      <td>3</td>\n      <td>[35.525, 51.1]</td>\n      <td>35.525</td>\n      <td>51.100</td>\n    </tr>\n    <tr>\n      <th>17992</th>\n      <td>59</td>\n      <td>0</td>\n      <td>[pool, [35.525, 51.1]]</td>\n      <td>[restaurant, [35.815, 51.32]]</td>\n      <td>2024-01-30 20:09:00</td>\n      <td>2024-01-30 21:19:00</td>\n      <td>36.80</td>\n      <td>20</td>\n      <td>70.0</td>\n      <td>3</td>\n      <td>[35.525, 51.1]</td>\n      <td>35.525</td>\n      <td>51.100</td>\n      <td>4</td>\n      <td>[35.815, 51.32]</td>\n      <td>35.815</td>\n      <td>51.320</td>\n    </tr>\n    <tr>\n      <th>17993</th>\n      <td>59</td>\n      <td>0</td>\n      <td>[restaurant, [35.815, 51.32]]</td>\n      <td>[home, [35.95, 51.225]]</td>\n      <td>2024-01-30 21:49:00</td>\n      <td>2024-01-30 22:21:00</td>\n      <td>11.22</td>\n      <td>21</td>\n      <td>32.0</td>\n      <td>4</td>\n      <td>[35.815, 51.32]</td>\n      <td>35.815</td>\n      <td>51.320</td>\n      <td>1</td>\n      <td>[35.95, 51.225]</td>\n      <td>35.950</td>\n      <td>51.225</td>\n    </tr>\n  </tbody>\n</table>\n<p>17994 rows × 17 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, train_label_encoder = feature_engineering_neural_net(data_train)\n",
    "data_test, test_label_encoder = feature_engineering_neural_net(data_test)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "       user_id  Day  hour_of_start  trip_duration  origin_label  origin_lat  \\\n10541       36    4             13           50.0             6      35.625   \n6162        20    1             13           34.0             6      35.875   \n1166         4    3             13           13.0             4      35.705   \n9320        31    4             12           86.0             5      35.625   \n9193        31    6             22           95.0             4      35.510   \n...        ...  ...            ...            ...           ...         ...   \n3696        13    1             15          106.0             4      35.995   \n15415       52    1             17           36.0             6      35.625   \n3918        13    4             14            6.0             4      35.650   \n5291        18    1              7           62.0             1      35.950   \n13734       45    1             13           23.0             4      35.970   \n\n       origin_lon  price  \n10541      51.125  26.61  \n6162       51.375  21.66  \n1166       51.295  10.00  \n9320       51.250  34.91  \n9193       51.155  41.62  \n...           ...    ...  \n3696       51.000  44.85  \n15415      51.125  20.36  \n3918       51.385  16.16  \n5291       51.280  26.83  \n13734      51.215  22.01  \n\n[14395 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>Day</th>\n      <th>hour_of_start</th>\n      <th>trip_duration</th>\n      <th>origin_label</th>\n      <th>origin_lat</th>\n      <th>origin_lon</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10541</th>\n      <td>36</td>\n      <td>4</td>\n      <td>13</td>\n      <td>50.0</td>\n      <td>6</td>\n      <td>35.625</td>\n      <td>51.125</td>\n      <td>26.61</td>\n    </tr>\n    <tr>\n      <th>6162</th>\n      <td>20</td>\n      <td>1</td>\n      <td>13</td>\n      <td>34.0</td>\n      <td>6</td>\n      <td>35.875</td>\n      <td>51.375</td>\n      <td>21.66</td>\n    </tr>\n    <tr>\n      <th>1166</th>\n      <td>4</td>\n      <td>3</td>\n      <td>13</td>\n      <td>13.0</td>\n      <td>4</td>\n      <td>35.705</td>\n      <td>51.295</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>9320</th>\n      <td>31</td>\n      <td>4</td>\n      <td>12</td>\n      <td>86.0</td>\n      <td>5</td>\n      <td>35.625</td>\n      <td>51.250</td>\n      <td>34.91</td>\n    </tr>\n    <tr>\n      <th>9193</th>\n      <td>31</td>\n      <td>6</td>\n      <td>22</td>\n      <td>95.0</td>\n      <td>4</td>\n      <td>35.510</td>\n      <td>51.155</td>\n      <td>41.62</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3696</th>\n      <td>13</td>\n      <td>1</td>\n      <td>15</td>\n      <td>106.0</td>\n      <td>4</td>\n      <td>35.995</td>\n      <td>51.000</td>\n      <td>44.85</td>\n    </tr>\n    <tr>\n      <th>15415</th>\n      <td>52</td>\n      <td>1</td>\n      <td>17</td>\n      <td>36.0</td>\n      <td>6</td>\n      <td>35.625</td>\n      <td>51.125</td>\n      <td>20.36</td>\n    </tr>\n    <tr>\n      <th>3918</th>\n      <td>13</td>\n      <td>4</td>\n      <td>14</td>\n      <td>6.0</td>\n      <td>4</td>\n      <td>35.650</td>\n      <td>51.385</td>\n      <td>16.16</td>\n    </tr>\n    <tr>\n      <th>5291</th>\n      <td>18</td>\n      <td>1</td>\n      <td>7</td>\n      <td>62.0</td>\n      <td>1</td>\n      <td>35.950</td>\n      <td>51.280</td>\n      <td>26.83</td>\n    </tr>\n    <tr>\n      <th>13734</th>\n      <td>45</td>\n      <td>1</td>\n      <td>13</td>\n      <td>23.0</td>\n      <td>4</td>\n      <td>35.970</td>\n      <td>51.215</td>\n      <td>22.01</td>\n    </tr>\n  </tbody>\n</table>\n<p>14395 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_train[['user_id', 'Day', 'hour_of_start', 'trip_duration', 'origin_label', 'origin_lat', 'origin_lon', 'price']]\n",
    "y = data_train['destination_label']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "X_test = data_test[['user_id', 'Day', 'hour_of_start', 'trip_duration', 'origin_label', 'origin_lat', 'origin_lon', 'price']]\n",
    "y_test = data_test['destination_label']\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "10541    4\n6162     4\n1166     5\n9320     4\n9193     1\n        ..\n3696     6\n15415    3\n3918     6\n5291     5\n13734    5\nName: destination_label, Length: 14395, dtype: int32"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'user_id': [36 20  4 31 35 57 25 39 16  5 34  2 14 43 23 38 41 59 48 46 11 49 24 21\n",
      "  9 40 47 17 15 19 28 22 18 13 55  8  1 30 26 58 33 32 42 51 12  0 52 45\n",
      "  6 50 53 54 10 29 37 27  3 56  7 44]\n",
      "Unique values in 'Day': [4 1 3 6 2 0 5]\n",
      "Unique values in 'hour_of_start': [13 12 22  7 14 21  8  9 11 17 20  6 23 15 16 19 10 18]\n",
      "Unique values in 'trip_duration': [ 50.  34.  13.  86.  95.  14.  31.  36.   6.  79.  65.   2.  55.  46.\n",
      "  37.  29.  80.  17.  63.   9.  45.  27.  28.  15.  19.  22.  67.  60.\n",
      "  32.  10.  20.  16.  25.  74.  23.  68.  24.  40.  21.  54.  62.  75.\n",
      "  49.  58.  78.  26.  61.  30.  35.   7.  33.  73.  94.  12. 105.  42.\n",
      "  18.  43.  69.   5.  64.  52.  93.  11.  71.  41.  82.   8.  53.   4.\n",
      "   3.  56.  39.   1.  38.  47.  48.  76.  85.  66. 108.  89.  51.  44.\n",
      " 110.  72.  77.  81.  70.  83.  99.  59.  57. 104.  84. 103. 107. 128.\n",
      " 106. 113.  96. 102.  91. 101. 100.  88.  87.  90.  92.  98. 114. 109.\n",
      "  97. 123. 112. 122. 111. 126. 120. 115. 121. 135. 118. 132. 119. 127.\n",
      " 134. 117. 116.]\n",
      "Unique values in 'origin_label': [6 4 5 1 0 3 2]\n",
      "Unique values in 'origin_lat': [35.625 35.875 35.705 35.51  35.945 35.745 35.84  36.    35.53  35.5\n",
      " 35.8   35.69  35.64  35.71  35.82  35.81  35.93  35.975 35.565 35.735\n",
      " 35.75  35.89  35.955 35.74  35.555 35.99  35.815 35.675 35.68  35.575\n",
      " 35.7   35.83  35.9   35.765 35.505 35.785 35.525 35.55  35.725 35.52\n",
      " 35.76  35.95  35.65  35.905 35.855 35.97  35.775 35.77  35.615 35.635\n",
      " 35.535 35.805 35.62  35.845 35.865 35.54  35.595 35.995 35.98  35.545\n",
      " 35.825 35.56  35.59  35.91 ]\n",
      "Unique values in 'origin_lon': [51.125 51.375 51.295 51.25  51.155 51.415 51.465 51.24  51.085 51.485\n",
      " 51.29  51.1   51.12  51.09  51.225 51.11  51.235 51.06  51.2   51.385\n",
      " 51.315 51.185 51.045 51.195 51.18  51.32  51.31  51.135 51.15  51.115\n",
      " 51.495 51.075 51.445 51.17  51.3   51.285 51.435 51.035 51.35  51.5\n",
      " 51.215 51.165 51.275 51.21  51.4   51.245 51.175 51.37  51.47  51.305\n",
      " 51.345 51.27  51.46  51.    51.13  51.26  51.475 51.025 51.39  51.05\n",
      " 51.145 51.095 51.42  51.28  51.19 ]\n",
      "Unique values in 'price': [26.61 21.66 10.   ... 45.21 36.3  44.85]\n"
     ]
    }
   ],
   "source": [
    "for column in X_train.columns:\n",
    "    unique_values = X_train[column].unique()\n",
    "    print(f\"Unique values in '{column}': {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id            int64\n",
      "Day                int64\n",
      "hour_of_start      int32\n",
      "trip_duration    float64\n",
      "origin_label       int32\n",
      "origin_lat       float64\n",
      "origin_lon       float64\n",
      "price            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Based on your features and how you extracted them, you may need to use some encodings for your data. For example, if you have different classes as names (`str` data type. E.g. \"gym\") you need to make it a numeric value in order to feed it into your neural network. You can use `sklearn`'s functions (such as `LabelEncoder`, `OneHotEncoder`, `StandardScaler`, etc.) to do these kind of stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# done in the previous part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create `train_dataset` and its loader, also create `test_dataset` and its loader. You should also create `val_dataset` and its loader if you want to use validation set. You may need to implement a custom `torch.Dataset` class for your ease. Your loaders should be able to load data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        return torch.tensor(feature, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, you should implement your neural network model. You should use `pytorch`. **Note** that you should plot the loss function of your model during the training phase. (on both training and validation sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        # Define the architecture of the network\n",
    "        self.fc1 = nn.Linear(input_dim, 64) # First hidden layer\n",
    "        self.fc2 = nn.Linear(64, 64)        # Second hidden layer\n",
    "        self.fc3 = nn.Linear(64, output_dim) # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) # Activation function for hidden layer\n",
    "        x = F.relu(self.fc2(x)) # Activation function for hidden layer\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "number_of_unique_destinations = data_train['destination_label'].nunique()\n",
    "model = MLP(input_dim=8, output_dim=number_of_unique_destinations)\n",
    "criterion = nn.CrossEntropyLoss()  # Common choice for classification tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Common choice for optimization\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "    # Plotting training and validation losses\n",
    "    plt.plot(range(1, epochs+1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Training Loss: 1.4009, Validation Loss: 1.2105\n",
      "Epoch 2/100 - Training Loss: 1.1304, Validation Loss: 1.1223\n",
      "Epoch 3/100 - Training Loss: 1.0677, Validation Loss: 1.0700\n",
      "Epoch 4/100 - Training Loss: 1.0107, Validation Loss: 1.0402\n",
      "Epoch 5/100 - Training Loss: 0.9441, Validation Loss: 0.9516\n",
      "Epoch 6/100 - Training Loss: 0.8823, Validation Loss: 0.9105\n",
      "Epoch 7/100 - Training Loss: 0.8279, Validation Loss: 0.8558\n",
      "Epoch 8/100 - Training Loss: 0.7809, Validation Loss: 0.7856\n",
      "Epoch 9/100 - Training Loss: 0.7320, Validation Loss: 0.7299\n",
      "Epoch 10/100 - Training Loss: 0.6834, Validation Loss: 0.6925\n",
      "Epoch 11/100 - Training Loss: 0.6458, Validation Loss: 0.6707\n",
      "Epoch 12/100 - Training Loss: 0.6251, Validation Loss: 0.6386\n",
      "Epoch 13/100 - Training Loss: 0.6013, Validation Loss: 0.6086\n",
      "Epoch 14/100 - Training Loss: 0.5778, Validation Loss: 0.5817\n",
      "Epoch 15/100 - Training Loss: 0.5554, Validation Loss: 0.5709\n",
      "Epoch 16/100 - Training Loss: 0.5347, Validation Loss: 0.5434\n",
      "Epoch 17/100 - Training Loss: 0.5194, Validation Loss: 0.5439\n",
      "Epoch 18/100 - Training Loss: 0.5028, Validation Loss: 0.5340\n",
      "Epoch 19/100 - Training Loss: 0.4857, Validation Loss: 0.4933\n",
      "Epoch 20/100 - Training Loss: 0.4655, Validation Loss: 0.4828\n",
      "Epoch 21/100 - Training Loss: 0.4543, Validation Loss: 0.4684\n",
      "Epoch 22/100 - Training Loss: 0.4419, Validation Loss: 0.4649\n",
      "Epoch 23/100 - Training Loss: 0.4304, Validation Loss: 0.4342\n",
      "Epoch 24/100 - Training Loss: 0.4175, Validation Loss: 0.4600\n",
      "Epoch 25/100 - Training Loss: 0.4082, Validation Loss: 0.4178\n",
      "Epoch 26/100 - Training Loss: 0.3991, Validation Loss: 0.4190\n",
      "Epoch 27/100 - Training Loss: 0.3937, Validation Loss: 0.4113\n",
      "Epoch 28/100 - Training Loss: 0.3789, Validation Loss: 0.3889\n",
      "Epoch 29/100 - Training Loss: 0.3699, Validation Loss: 0.4169\n",
      "Epoch 30/100 - Training Loss: 0.3639, Validation Loss: 0.3827\n",
      "Epoch 31/100 - Training Loss: 0.3488, Validation Loss: 0.3768\n",
      "Epoch 32/100 - Training Loss: 0.3441, Validation Loss: 0.3717\n",
      "Epoch 33/100 - Training Loss: 0.3396, Validation Loss: 0.3751\n",
      "Epoch 34/100 - Training Loss: 0.3269, Validation Loss: 0.3416\n",
      "Epoch 35/100 - Training Loss: 0.3188, Validation Loss: 0.3819\n",
      "Epoch 36/100 - Training Loss: 0.3196, Validation Loss: 0.3689\n",
      "Epoch 37/100 - Training Loss: 0.3135, Validation Loss: 0.3285\n",
      "Epoch 38/100 - Training Loss: 0.3065, Validation Loss: 0.3329\n",
      "Epoch 39/100 - Training Loss: 0.3009, Validation Loss: 0.3137\n",
      "Epoch 40/100 - Training Loss: 0.2937, Validation Loss: 0.3388\n",
      "Epoch 41/100 - Training Loss: 0.2937, Validation Loss: 0.3264\n",
      "Epoch 42/100 - Training Loss: 0.2872, Validation Loss: 0.3207\n",
      "Epoch 43/100 - Training Loss: 0.2913, Validation Loss: 0.3278\n",
      "Epoch 44/100 - Training Loss: 0.2841, Validation Loss: 0.3003\n",
      "Epoch 45/100 - Training Loss: 0.2788, Validation Loss: 0.3377\n",
      "Epoch 46/100 - Training Loss: 0.2773, Validation Loss: 0.3175\n",
      "Epoch 47/100 - Training Loss: 0.2831, Validation Loss: 0.3145\n",
      "Epoch 48/100 - Training Loss: 0.2695, Validation Loss: 0.2996\n",
      "Epoch 49/100 - Training Loss: 0.2690, Validation Loss: 0.3000\n",
      "Epoch 50/100 - Training Loss: 0.2682, Validation Loss: 0.2959\n",
      "Epoch 51/100 - Training Loss: 0.2643, Validation Loss: 0.2800\n",
      "Epoch 52/100 - Training Loss: 0.2646, Validation Loss: 0.3025\n",
      "Epoch 53/100 - Training Loss: 0.2615, Validation Loss: 0.2958\n",
      "Epoch 54/100 - Training Loss: 0.2574, Validation Loss: 0.2916\n",
      "Epoch 55/100 - Training Loss: 0.2622, Validation Loss: 0.3090\n",
      "Epoch 56/100 - Training Loss: 0.2531, Validation Loss: 0.3344\n",
      "Epoch 57/100 - Training Loss: 0.2523, Validation Loss: 0.2760\n",
      "Epoch 58/100 - Training Loss: 0.2505, Validation Loss: 0.2944\n",
      "Epoch 59/100 - Training Loss: 0.2522, Validation Loss: 0.2736\n",
      "Epoch 60/100 - Training Loss: 0.2481, Validation Loss: 0.2708\n",
      "Epoch 61/100 - Training Loss: 0.2504, Validation Loss: 0.3087\n",
      "Epoch 62/100 - Training Loss: 0.2484, Validation Loss: 0.2588\n",
      "Epoch 63/100 - Training Loss: 0.2508, Validation Loss: 0.2778\n",
      "Epoch 64/100 - Training Loss: 0.2463, Validation Loss: 0.2728\n",
      "Epoch 65/100 - Training Loss: 0.2442, Validation Loss: 0.2717\n",
      "Epoch 66/100 - Training Loss: 0.2482, Validation Loss: 0.2990\n",
      "Epoch 67/100 - Training Loss: 0.2444, Validation Loss: 0.2749\n",
      "Epoch 68/100 - Training Loss: 0.2424, Validation Loss: 0.2634\n",
      "Epoch 69/100 - Training Loss: 0.2364, Validation Loss: 0.2772\n",
      "Epoch 70/100 - Training Loss: 0.2402, Validation Loss: 0.2740\n",
      "Epoch 71/100 - Training Loss: 0.2366, Validation Loss: 0.2645\n",
      "Epoch 72/100 - Training Loss: 0.2377, Validation Loss: 0.2680\n",
      "Epoch 73/100 - Training Loss: 0.2373, Validation Loss: 0.2580\n",
      "Epoch 74/100 - Training Loss: 0.2369, Validation Loss: 0.2607\n",
      "Epoch 75/100 - Training Loss: 0.2321, Validation Loss: 0.2859\n",
      "Epoch 76/100 - Training Loss: 0.2350, Validation Loss: 0.2706\n",
      "Epoch 77/100 - Training Loss: 0.2357, Validation Loss: 0.2674\n",
      "Epoch 78/100 - Training Loss: 0.2340, Validation Loss: 0.2686\n",
      "Epoch 79/100 - Training Loss: 0.2355, Validation Loss: 0.2624\n",
      "Epoch 80/100 - Training Loss: 0.2317, Validation Loss: 0.2770\n",
      "Epoch 81/100 - Training Loss: 0.2310, Validation Loss: 0.2843\n",
      "Epoch 82/100 - Training Loss: 0.2341, Validation Loss: 0.2522\n",
      "Epoch 83/100 - Training Loss: 0.2265, Validation Loss: 0.2747\n",
      "Epoch 84/100 - Training Loss: 0.2319, Validation Loss: 0.2573\n",
      "Epoch 85/100 - Training Loss: 0.2298, Validation Loss: 0.2533\n",
      "Epoch 86/100 - Training Loss: 0.2248, Validation Loss: 0.2595\n",
      "Epoch 87/100 - Training Loss: 0.2290, Validation Loss: 0.2475\n",
      "Epoch 88/100 - Training Loss: 0.2373, Validation Loss: 0.2570\n",
      "Epoch 89/100 - Training Loss: 0.2261, Validation Loss: 0.2568\n",
      "Epoch 90/100 - Training Loss: 0.2243, Validation Loss: 0.2459\n",
      "Epoch 91/100 - Training Loss: 0.2277, Validation Loss: 0.2514\n",
      "Epoch 92/100 - Training Loss: 0.2271, Validation Loss: 0.2499\n",
      "Epoch 93/100 - Training Loss: 0.2230, Validation Loss: 0.2528\n",
      "Epoch 94/100 - Training Loss: 0.2262, Validation Loss: 0.2382\n",
      "Epoch 95/100 - Training Loss: 0.2230, Validation Loss: 0.2516\n",
      "Epoch 96/100 - Training Loss: 0.2221, Validation Loss: 0.2624\n",
      "Epoch 97/100 - Training Loss: 0.2188, Validation Loss: 0.2694\n",
      "Epoch 98/100 - Training Loss: 0.2251, Validation Loss: 0.2477\n",
      "Epoch 99/100 - Training Loss: 0.2208, Validation Loss: 0.2443\n",
      "Epoch 100/100 - Training Loss: 0.2160, Validation Loss: 0.2542\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluate Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Report the model's accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test data is: 90.93%\n"
     ]
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(model, test_loader)\n",
    "print(f'Accuracy of the model on the test data is: {accuracy:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Just for the sake of curiosity, let's take a random sample from the test set and see the model's prediction. So, randomly choose a sample from the test set and print it out (to see its features and also the correct output). Then, feed the features into your model and see what it predicts. Is it correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      user_id  Day  hour_of_start  trip_duration  origin_label  origin_lat  \\\n4201        3    2              7           19.0             1       35.62   \n\n      origin_lon  price  \n4201      51.275   10.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>Day</th>\n      <th>hour_of_start</th>\n      <th>trip_duration</th>\n      <th>origin_label</th>\n      <th>origin_lat</th>\n      <th>origin_lon</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4201</th>\n      <td>3</td>\n      <td>2</td>\n      <td>7</td>\n      <td>19.0</td>\n      <td>1</td>\n      <td>35.62</td>\n      <td>51.275</td>\n      <td>10.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = X_test.sample(n=1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "4201    [work, [35.625, 51.375]]\nName: destination, dtype: object"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.iloc[sample.index]['destination']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor = torch.tensor(sample.values, dtype=torch.float32)\n",
    "sample_tensor = sample_tensor.reshape(1, -1)\n",
    "with torch.no_grad():\n",
    "    output = model(sample_tensor)\n",
    "    _, predicted_label = torch.max(output, 1)\n",
    "predicted_label.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "6"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[sample.index].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, use the inverse transform of the encoding you used earlier to get the name of the destination from the predicted class. Print it out and see if it's correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'work'"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_encoder.inverse_transform(predicted_label.numpy())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**QUESTION**: What do you think about this approach? Is it a good idea to use Neural Networks for this problem? Why (or why not)? If the patterns in our datatset (passengers' history) get more complicated, will our model be robust to it in comparison to other models?\n",
    "\n",
    "Your Answer:\n",
    "***\n",
    "\n",
    "***Using neural networks for this type of prediction problem can be effective, especially if the dataset is large and contains complex, non-linear relationships. Neural networks excel in learning intricate patterns from high-dimensional data, but they require sufficient data and computational resources. However, they might be overkill for simpler, smaller datasets and can be prone to overfitting without proper regularization.***\n",
    "\n",
    "***Compared to KNN and XGBoost, neural networks generally handle high-dimensional, complex data better but are more resource-intensive and less interpretable. KNN is simpler and works well with smaller datasets but struggles with high dimensionality and larger datasets. XGBoost is powerful for structured/tabular data, offers good performance with less computational cost than neural networks, and is often easier to tune and interpret than deep learning models.***\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# How to Submit:\n",
    "\n",
    "Please upload your notebook (`.ipynb`) compressed (as a `.zip` file) or uncompressed on Quera. **Note** that for each part, the accuracy of your model on the given test dataset is important. So, your accuracy should be **at least** same as ours (or better). Also, we will check your code after the submission. So, please make sure that there are no **data snooping** or **data leakage** in your code. You **can not** use the test data in any stages for your model, except for the final evaluation part! So, please be ware of that, or you may lose points.\n",
    "\n",
    "Your project is graded via 2 main parts: \n",
    "1. Checking out your implementation (to check if there are no \"data snooping\" and \"data leakage\") \n",
    "   \n",
    "2. Checking accuracies of your models on the test set. \n",
    "\n",
    "3. Running again your code by you in the \"in-person\" session and hearing your explanations (on the parts that we asked questions about the models, overfitting and etc. with tag \"QUESTION\" in the notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}